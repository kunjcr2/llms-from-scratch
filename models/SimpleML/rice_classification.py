# -*- coding: utf-8 -*-
"""rice_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ErQZ45eISTz2iGBvholgywb4MLBVDUw9
"""

!pip install -q opendatasets
import opendatasets as od

# Downloads the dataset, needs kaggle username and token
od.download("https://www.kaggle.com/datasets/mssmartypants/rice-type-classification")

import torch
import torch.nn as nn
from torch.optim import Adam
from torch.utils.data import Dataset, DataLoader
from torchsummary import summary

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f'Using {device}')

data_df = pd.read_csv('/content/rice-type-classification/riceClassification.csv')
data_df.head()

print(f'Before: {data_df.shape}')
data_df.dropna(inplace=True)
data_df.drop(["id"], axis=1, inplace=True)
print(f'After: {data_df.shape}')

print(data_df["Class"].value_counts())

og_df = data_df.copy()

# Normalizing by the mean of absolute values of each columns
for col in data_df.columns:
  data_df[col] = data_df[col]/data_df[col].abs().mean()

data_df.head()

# Breaking in the X, y and train, test, val
X = np.array(data_df.iloc[:, :-1])
y = np.array(data_df.iloc[:, -1])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)

print(f'X_train: {X_train.shape}')
print(f'y_train: {y_train.shape}')
print(f'X_val: {X_val.shape}')
print(f'y_val: {y_val.shape}')
print(f'X_test: {X_test.shape}')
print(f'y_test: {y_test.shape}')

# Putting the data down in Datasets format and tensors under-the-hood
class dataset(Dataset):
  def __init__(self, X, y):
    self.X = torch.tensor(X, dtype=torch.float32).to(device)
    self.y = torch.tensor(y, dtype=torch.int64).to(device)

  def __len__(self):
    return len(self.X)

  def __getitem__(self, index):
    return self.X[index], self.y[index]

training_data = dataset(X_train, y_train)
val_data = dataset(X_val, y_val)
test_data = dataset(X_test, y_test)

print(training_data.X.shape)
print(training_data.y.shape)
print(test_data.X.shape)
print(test_data.y.shape)
print(val_data.X.shape)
print(val_data.y.shape)

# Yupp, DataLoaders
train_loader = DataLoader(
    training_data,
    batch_size=8,
    shuffle=True
)

val_loader = DataLoader(
    val_data,
    batch_size=8,
    shuffle=True
)

test_loader = DataLoader(
    test_data,
    batch_size=8,
    shuffle=True
)

# Model with about 240 params, simple Linear with a Sigmoid head
HIDDEN_N = 20

class Model(nn.Module):
  def __init__(self):
    super().__init__()

    self.input_layer = nn.Linear(X.shape[1], HIDDEN_N)
    self.layer_1 = nn.Linear(HIDDEN_N, 1)
    self.sigmoid = nn.Sigmoid()

  def forward(self, x):
    return self.sigmoid(
        self.layer_1(
            self.input_layer(x)
          )
        )

model = Model().to(device)

summary(model, (X.shape[1],))

loss_fn = nn.BCELoss() # Binary Cross Entropy Loss
optim = Adam(model.parameters(), lr=0.001, weight_decay=0.001) # Adam Optimizer

train_loss_plot = []
val_loss_plot = []
train_acc_plot = []
val_acc_plot = []

epochs = 100

for epoch in range(epochs):

    # =========================
    # TRAIN
    # =========================
    model.train()

    train_loss = 0.0
    train_correct = 0
    train_samples = 0

    for inputs, labels in train_loader:
        labels = labels.float()

        optim.zero_grad()

        preds = model(inputs).squeeze(1)
        loss = loss_fn(preds, labels)

        loss.backward()
        optim.step()

        train_loss += loss.item()

        train_correct += (preds.round() == labels).sum().item()
        train_samples += labels.size(0)

    train_loss /= len(train_loader)
    train_acc = (train_correct / train_samples) * 100

    train_loss_plot.append(train_loss)
    train_acc_plot.append(train_acc)

    # =========================
    # VALIDATION
    # =========================
    model.eval()

    val_loss = 0.0
    val_correct = 0
    val_samples = 0

    with torch.no_grad():
        for inputs, labels in val_loader:
            labels = labels.float()

            preds = model(inputs).squeeze(1)
            loss = loss_fn(preds, labels)

            val_loss += loss.item()
            val_correct += (preds.round() == labels).sum().item()
            val_samples += labels.size(0)

    val_loss /= len(val_loader)
    val_acc = (val_correct / val_samples) * 100

    val_loss_plot.append(val_loss)
    val_acc_plot.append(val_acc)

    # =========================
    # LOG
    # =========================
    if epoch % 5 == 0:
        print(
            f'Epoch {epoch+1:03d} | '
            f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | '
            f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%'
        )

with torch.no_grad():
  acc_test = 0

  for inputs, labels in test_loader:
    labels = labels.float()
    preds = model(inputs).squeeze(1)
    acc_test += ((preds.round() == labels).sum().item() / labels.size(0))

  acc_test /= len(test_loader)

print(f"Accuracy: {round(acc_test*100, 4)}%")

from matplotlib import axes
fig, axs = plt.subplots(1, 2, figsize=(15, 5))
axs[0].plot(train_loss_plot, label='Train Loss')
axs[0].plot(val_loss_plot, label='Val Loss')
axs[0].set_xlabel('Epochs')
axs[0].set_ylabel('Loss')
axs[0].set_title('Loss vs Epochs')
axs[0].legend()

axs[1].plot(train_acc_plot, label='Train Acc')
axs[1].plot(val_acc_plot, label='Val Acc')
axs[1].set_xlabel('Epochs')
axs[1].set_ylabel('Accuracy')
axs[1].set_title('Accuracy vs Epochs')
axs[1].legend()

Area = 2353/og_df['Area'].abs().max()
MajorAL = 81/og_df['MajorAxisLength'].abs().max()
MinorAL = 42/og_df['MinorAxisLength'].abs().max()
Eccentricity = 32/og_df['Eccentricity'].abs().max()
ConvexArea = 12/og_df['ConvexArea'].abs().max()
EquivDiameter = 33/og_df['EquivDiameter'].abs().max()
Extent = 98/og_df['Extent'].abs().max()
Perimeter = 927/og_df['Perimeter'].abs().max()
Roundness = 677/og_df['Roundness'].abs().max()
AspectRation = 24/og_df['AspectRation'].abs().max()

input = torch.tensor([Area, MajorAL, MinorAL, Eccentricity, ConvexArea, EquivDiameter, Extent, Perimeter, Roundness, AspectRation], dtype=torch.float32).to(device)
pred = model(input)
print(pred)

