"""Animal Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11Q4JDH16JvDYzg-RriMJIADU9-NSR-1b
"""

# !pip install -q opendatasets
import opendatasets as od
od.download("https://www.kaggle.com/datasets/andrewmvd/animal-faces")

import torch
from torch import nn
from torch.optim import Adam
from torchvision.transforms import transforms # Preprocessing images
from torch.utils.data import Dataset, DataLoader

from sklearn.preprocessing import LabelEncoder # Converts classes to 0-(n-1) categories
import matplotlib.pyplot as plt
from PIL import Image
import pandas as pd
import numpy as np
import os

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f'Using {device}')

image_path = []
labels = []

# Getting all the images and labels TOGETHER
for i in os.listdir("/content/animal-faces/afhq"):
  for label in os.listdir(f"/content/animal-faces/afhq/{i}"):
    for image in os.listdir(f"/content/animal-faces/afhq/{i}/{label}"):
      image_path.append(f"/content/animal-faces/afhq/{i}/{label}/{image}")
      labels.append(label)

df = pd.DataFrame(zip(image_path, labels), columns=["image_path", "label"])

print(df["label"].value_counts())
df.head()

# Splitting the dataset into train, val and test
train = df.sample(frac=0.7)
test = df.drop(train.index)

val = test.sample(frac=0.5)
test = test.drop(val.index)

print(f"Train size: {train.shape}")
print(f"Test size: {test.shape}")
print(f"Val size: {val.shape}")

# Label encoding
label_encoder = LabelEncoder()
label_encoder.fit(df["label"])

# Composes images so that they all have same properties
transform = transforms.Compose([
    transforms.Resize((128,128)),
    transforms.ToTensor(),
    transforms.ConvertImageDtype(torch.float32),
])

class CustomImageDataset(Dataset):
  """Custom dataset for images."""
  def __init__(self, df, transform=None):
    self.df = df
    self.transform = transform
    self.labels = torch.tensor(label_encoder.transform(self.df["label"]))

  def __len__(self):
    return self.df.shape[0]

  def __getitem__(self, idx):
    img_path = self.df.iloc[idx, 0]
    label = self.labels[idx]

    image = Image.open(img_path).convert('RGB')

    if self.transform:
      image = self.transform(image).to(device)

    return image, label

train_ds = CustomImageDataset(train, transform)
test_ds = CustomImageDataset(test, transform)
val_ds = CustomImageDataset(val, transform)

# Visualizing the images in 3x3 grid
n_rows = 3
n_cols = 3

f, axarr = plt.subplots(n_rows, n_cols)
for row in range(n_rows):
  for col in range(n_cols):
    image = Image.open(df.sample(n=1)["image_path"].iloc[0]).convert("RGB")
    axarr[row, col].imshow(image)
    axarr[row, col].axis("off")

# Hyperparameters
LR = 1e-4
BATCH_SIZE = 16
EPOCHS = 10

# DataLoaders
train_loader = DataLoader(
    train_ds,
    batch_size=BATCH_SIZE,
    shuffle=True,
)

test_loader = DataLoader(
    test_ds,
    batch_size=BATCH_SIZE,
    shuffle=True,
)

val_loader = DataLoader(
    val_ds,
    batch_size=BATCH_SIZE,
    shuffle=True,
)

class net(nn.Module):
  """Simple 3 layer Convolutional Neural Network."""
  def __init__(self):
    super().__init__()

    # input: 3x128x128
    self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)

    self.pooling = nn.MaxPool2d(2,2)
    self.relu = nn.ReLU()
    self.flatten = nn.Flatten()
    self.linear = nn.Linear(128*16*16, 128)

    self.output = nn.Linear(128, len(df["label"].unique()))

  def forward(self, x):
    x = self.relu(self.pooling(self.conv1(x))) # 3x128x128 -> 32x64x64
    x = self.relu(self.pooling(self.conv2(x))) # 32x64x64 -> 64x32x32
    x = self.relu(self.pooling(self.conv3(x))) # 64x32x32 -> 128x16x16
    x = self.output(self.linear(self.flatten(x))) # 128x16x16 -> 3

    return x

model = net().to(device)

from torchsummary import summary
summary(model, (3, 128, 128)) # 4M params

# Loss and Optimizer
loss_fn = nn.CrossEntropyLoss()
optim = Adam(model.parameters(), lr=LR)

# Training
train_loss_plot = []
val_loss_plot = []
train_acc_plot = []
val_acc_plot = []

for epoch in range(EPOCHS):

    # =========================
    # TRAIN
    # =========================
    model.train()

    train_loss = 0.0
    train_correct = 0
    train_samples = 0

    for inputs, labels in train_loader:
        labels = labels.to(device) # Move labels to the same device as model

        optim.zero_grad()

        preds = model(inputs) # Removed .squeeze(1) as it's not appropriate for multi-class logits
        loss = loss_fn(preds, labels)

        loss.backward()
        optim.step()

        train_loss += loss.item()

        _, predicted = torch.max(preds.data, 1) # Correct way to get class predictions
        train_correct += (predicted == labels).sum().item()
        train_samples += labels.size(0)

    train_loss /= len(train_loader)
    train_acc = (train_correct / train_samples) * 100

    train_loss_plot.append(train_loss)
    train_acc_plot.append(train_acc)

    # =========================
    # VALIDATION
    # =========================
    model.eval()

    val_loss = 0.0
    val_correct = 0
    val_samples = 0

    with torch.no_grad():
        for inputs, labels in val_loader:
            labels = labels.to(device) # Move labels to the same device as model

            preds = model(inputs) # Removed .squeeze(1)
            loss = loss_fn(preds, labels)

            val_loss += loss.item()
            _, predicted = torch.max(preds.data, 1) # Correct way to get class predictions
            val_correct += (predicted == labels).sum().item()
            val_samples += labels.size(0)

    val_loss /= len(val_loader)
    val_acc = (val_correct / val_samples) * 100

    val_loss_plot.append(val_loss)
    val_acc_plot.append(val_acc)

    # =========================
    # LOG
    # =========================
    if epoch % 5 == 0:
        print(
            f'Epoch {epoch+1:03d} | '
            f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | '
            f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%'
        )

# =========================
# TEST
# =========================
with torch.no_grad():
  correct_test = 0
  total_test_samples = 0

  for inputs, labels in test_loader:
    inputs = inputs.to(device) # Ensure inputs are on the device
    labels = labels.to(device) # Ensure labels are on the device

    preds = model(inputs) # model(inputs) outputs (batch_size, num_classes)
    _, predicted = torch.max(preds.data, 1) # Get the predicted class indices

    total_test_samples += labels.size(0)
    correct_test += (predicted == labels).sum().item()

  acc_test = (correct_test / total_test_samples) * 100 if total_test_samples > 0 else 0

print(f"Accuracy: {round(acc_test, 4)}%")

# =========================
# PLOTTING
# =========================
from matplotlib import axes
fig, axs = plt.subplots(1, 2, figsize=(15, 5))
axs[0].plot(train_loss_plot, label='Train Loss')
axs[0].plot(val_loss_plot, label='Val Loss')
axs[0].set_xlabel('Epochs')
axs[0].set_ylabel('Loss')
axs[0].set_title('Loss vs Epochs')
axs[0].legend()

axs[1].plot(train_acc_plot, label='Train Acc')
axs[1].plot(val_acc_plot, label='Val Acc')
axs[1].set_xlabel('Epochs')
axs[1].set_ylabel('Accuracy')
axs[1].set_title('Accuracy vs Epochs')
axs[1].legend()

